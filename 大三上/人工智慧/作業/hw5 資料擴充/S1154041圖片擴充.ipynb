{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# 解壓縮資料夾所在的目錄路徑\n",
    "original_dataset_dir = r'./dogs-vs-cats/train' \n",
    "# 用來儲存少量資料集的目錄位置\n",
    "base_dir = r'./cats_and_dogs_small' \n",
    "if not os.path.isdir(base_dir): os.mkdir(base_dir)  # 如果目錄不存在, 才建立目錄\n",
    "\n",
    "# 分拆成訓練、驗證與測試目錄位置\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.isdir(train_dir): os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')  \n",
    "if not os.path.isdir(validation_dir): os.mkdir(validation_dir)\n",
    "    \n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.isdir(test_dir): os.mkdir(test_dir)\n",
    "\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if not os.path.isdir(train_cats_dir): \n",
    "    os.mkdir(train_cats_dir) # 用來訓練貓圖片的目錄位置\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if not os.path.isdir(train_dogs_dir): \n",
    "    os.mkdir(train_dogs_dir) # 用來訓練狗圖片的目錄位置\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if not os.path.isdir(validation_cats_dir): \n",
    "    os.mkdir(validation_cats_dir) # 用來驗證貓圖片的目錄位置\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.isdir(validation_dogs_dir): \n",
    "    os.mkdir(validation_dogs_dir) # 用來驗證狗圖片的目錄位置\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if not os.path.isdir(test_cats_dir): \n",
    "    os.mkdir(test_cats_dir) # 用來測試貓圖片的目錄位置\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.isdir(test_dogs_dir): \n",
    "    os.mkdir(test_dogs_dir) # 用來測試狗圖片的目錄位置\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 複製前面 1000 張貓圖片到 train_cats_dir 訓練目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張貓圖片到 validation_cats_dir 驗證目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張貓圖片到 test_cats_dir 測試目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製前面 1000 張狗圖片到 train_dogs_dir 訓練目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張狗圖片到 validation_dogs_dir 驗證目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張狗圖片到 test_dogs_dir 測試目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "print('複製完成')\n",
    "print('訓練用的貓照片張數:', len(os.listdir(train_cats_dir)))\n",
    "print('訓練用的狗照片張數:', len(os.listdir(train_dogs_dir)))\n",
    "print('驗證用的貓照片張數:', len(os.listdir(validation_cats_dir)))\n",
    "print('驗證用的狗照片張數:', len(os.listdir(validation_dogs_dir)))\n",
    "print('測試用的貓照片張數:', len(os.listdir(test_cats_dir)))\n",
    "print('測試用的狗照片張數:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout\n",
    "from keras.layers import Activation, Flatten, Input\n",
    "def buildModel(type):\n",
    "    if(type == 'A'):\n",
    "        model = Sequential([\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same', input_shape=(150, 150, 3)),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            Dense(64, activation = 'relu'),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    elif(type == 'B'):\n",
    "        model = Sequential([\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same', input_shape=(150, 150, 3)),\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            Dense(64, activation = 'relu'),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20, \n",
    "    class_mode='binary' # 兩個 class \n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "# for data_batch, labels_batch in train_generator:\n",
    "#     print('data batch shape:', data_batch.shape)\n",
    "#     print('labels batch shape:', labels_batch.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 5s 36ms/step - loss: 0.6929 - acc: 0.5080 - val_loss: 0.6922 - val_acc: 0.5410\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6898 - acc: 0.5585 - val_loss: 0.6866 - val_acc: 0.6000\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6792 - acc: 0.5830 - val_loss: 0.6697 - val_acc: 0.5950\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6558 - acc: 0.6345 - val_loss: 0.6481 - val_acc: 0.6300\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6353 - acc: 0.6550 - val_loss: 0.6444 - val_acc: 0.6170\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6187 - acc: 0.6660 - val_loss: 0.6434 - val_acc: 0.6120\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6097 - acc: 0.6825 - val_loss: 0.6591 - val_acc: 0.6050\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5936 - acc: 0.6860 - val_loss: 0.6059 - val_acc: 0.6700\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.5873 - acc: 0.6890 - val_loss: 0.6098 - val_acc: 0.6600\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5717 - acc: 0.7130 - val_loss: 0.6326 - val_acc: 0.6440\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.5616 - acc: 0.7075 - val_loss: 0.6315 - val_acc: 0.6570\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5564 - acc: 0.7090 - val_loss: 0.5936 - val_acc: 0.6740\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5411 - acc: 0.7245 - val_loss: 0.5761 - val_acc: 0.6960\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5363 - acc: 0.7330 - val_loss: 0.5730 - val_acc: 0.7070\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.5215 - acc: 0.7425 - val_loss: 0.5759 - val_acc: 0.7100\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5120 - acc: 0.7505 - val_loss: 0.5811 - val_acc: 0.6980\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.5060 - acc: 0.7485 - val_loss: 0.5840 - val_acc: 0.6930\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.4963 - acc: 0.7535 - val_loss: 0.5673 - val_acc: 0.7020\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4899 - acc: 0.7640 - val_loss: 0.5688 - val_acc: 0.7170\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.4828 - acc: 0.7670 - val_loss: 0.5665 - val_acc: 0.6990\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4716 - acc: 0.7705 - val_loss: 0.5651 - val_acc: 0.7080\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4633 - acc: 0.7800 - val_loss: 0.5582 - val_acc: 0.7140\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4540 - acc: 0.7815 - val_loss: 0.5607 - val_acc: 0.7210\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.4410 - acc: 0.7945 - val_loss: 0.5787 - val_acc: 0.7060\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4364 - acc: 0.7960 - val_loss: 0.6866 - val_acc: 0.6710\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4258 - acc: 0.8055 - val_loss: 0.5705 - val_acc: 0.7100\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4221 - acc: 0.8025 - val_loss: 0.5651 - val_acc: 0.7210\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.4020 - acc: 0.8170 - val_loss: 0.5947 - val_acc: 0.7160\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 3s 33ms/step - loss: 0.3907 - acc: 0.8180 - val_loss: 0.5846 - val_acc: 0.7220\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.3832 - acc: 0.8275 - val_loss: 0.5892 - val_acc: 0.7110\n"
     ]
    }
   ],
   "source": [
    "model = buildModel('A')\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 1e-4), metrics='acc')\n",
    "# 使用 fit 能跟 fit_generator 做到相同的效果 (較新的版本), 如果無法使用, 改用 fit_generator\n",
    "historyA = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "# 存模型\n",
    "model.save('cats_and_dogs_small_A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 6s 44ms/step - loss: 0.6932 - acc: 0.4945 - val_loss: 0.6931 - val_acc: 0.5250\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6932 - acc: 0.4925 - val_loss: 0.6929 - val_acc: 0.5450\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6926 - acc: 0.5115 - val_loss: 0.6910 - val_acc: 0.5010\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6888 - acc: 0.5320 - val_loss: 0.6853 - val_acc: 0.5560\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6783 - acc: 0.5720 - val_loss: 0.6779 - val_acc: 0.5640\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6687 - acc: 0.6040 - val_loss: 0.6754 - val_acc: 0.5630\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6655 - acc: 0.6000 - val_loss: 0.6709 - val_acc: 0.5800\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6598 - acc: 0.6110 - val_loss: 0.6729 - val_acc: 0.5720\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6560 - acc: 0.6115 - val_loss: 0.6649 - val_acc: 0.5900\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6522 - acc: 0.6235 - val_loss: 0.6646 - val_acc: 0.5900\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6493 - acc: 0.6260 - val_loss: 0.6649 - val_acc: 0.5920\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6473 - acc: 0.6245 - val_loss: 0.6604 - val_acc: 0.5910\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6424 - acc: 0.6315 - val_loss: 0.6611 - val_acc: 0.5970\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.6396 - acc: 0.6305 - val_loss: 0.6551 - val_acc: 0.6070\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 3s 35ms/step - loss: 0.6360 - acc: 0.6330 - val_loss: 0.6561 - val_acc: 0.6100\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6313 - acc: 0.6440 - val_loss: 0.6598 - val_acc: 0.6050\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6287 - acc: 0.6440 - val_loss: 0.6527 - val_acc: 0.6150\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 0.6254 - acc: 0.6505 - val_loss: 0.6527 - val_acc: 0.6100\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.6198 - acc: 0.6620 - val_loss: 0.6500 - val_acc: 0.6180\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6157 - acc: 0.6645 - val_loss: 0.6533 - val_acc: 0.6210\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 4s 36ms/step - loss: 0.6121 - acc: 0.6655 - val_loss: 0.6569 - val_acc: 0.6230\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6050 - acc: 0.6700 - val_loss: 0.6712 - val_acc: 0.6080\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 4s 35ms/step - loss: 0.6004 - acc: 0.6760 - val_loss: 0.6550 - val_acc: 0.6210\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 4s 40ms/step - loss: 0.5963 - acc: 0.6770 - val_loss: 0.6610 - val_acc: 0.6190\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 4s 45ms/step - loss: 0.5920 - acc: 0.6865 - val_loss: 0.6512 - val_acc: 0.6290\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.5850 - acc: 0.6895 - val_loss: 0.6669 - val_acc: 0.6060\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 4s 44ms/step - loss: 0.5777 - acc: 0.6910 - val_loss: 0.6624 - val_acc: 0.6220\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5723 - acc: 0.7015 - val_loss: 0.6703 - val_acc: 0.6080\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5674 - acc: 0.7010 - val_loss: 0.6710 - val_acc: 0.6360\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.5591 - acc: 0.7085 - val_loss: 0.6765 - val_acc: 0.6200\n"
     ]
    }
   ],
   "source": [
    "model = buildModel('B')\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 1e-4), metrics='acc')\n",
    "# 使用 fit 能跟 fit_generator 做到相同的效果 (較新的版本), 如果無法使用, 改用 fit_generator\n",
    "historyB = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "# 存模型\n",
    "model.save('cats_and_dogs_small_B.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showHistory(history, name):\n",
    "    # 把訓練過程畫出來\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(name+'acc.png')\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(name+'loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHistory(historyA, \"A\")\n",
    "showHistory(historyB, \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 經過擴充處理過後產出的圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定產生圖片的參數, 旋轉, 平移, 左右翻轉, 填充模式...\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 顯示圖片產生器產出的東西\n",
    "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
    "img_path = fnames[20]\n",
    "img = tf.keras.utils.load_img(img_path, target_size=(150, 150))\n",
    "imgarr = tf.keras.utils.img_to_array(img)\n",
    "imgarr = imgarr.reshape((1, ) + imgarr.shape)\n",
    "i = 0\n",
    "for batch in datagen.flow(imgarr, batch_size=1):\n",
    "    plt.figure(i)\n",
    "    imgplot = plt.imshow(tf.keras.utils.array_to_img(batch[0]))\n",
    "    i += 1\n",
    "    if i % 4 == 0:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生圖片過後再訓練一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('A')\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255) # 驗證集不需要擴充, 跟之前一樣\n",
    "# 設定產生圖片的參數, 旋轉, 平移, 左右翻轉, 填充模式...\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "train_samples = train_generator.samples\n",
    "validation_samples = validation_generator.samples\n",
    "batch_size = 32\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = validation_samples // batch_size\n",
    "# historyA_extend = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     epochs=30,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_steps\n",
    "# )\n",
    "historyA_extend = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "model.save('cats_and_dogs_small_A_extend.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('B')\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=['acc'])\n",
    "historyB_extend = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "model.save('cats_and_dogs_small_B_extend.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHistory(historyA_extend, \"A_extend_\")\n",
    "showHistory(historyB_extend, \"B_extend_\")\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.legend()\n",
    "# plt.savefig('acc2.png')\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.legend()\n",
    "# plt.savefig('loss2.png')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
