{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "資料來源: [Kaggle](https://www.kaggle.com/c/dogs-vs-cats) <br/>\n",
    "需要登入 Kaggle，到設定頁面驗證自己的手機號碼， <br/>\n",
    "來到 Data 區塊選擇加入比賽，才能夠下載資料。 <br/>\n",
    "創建一個新的資料夾\"dogs-vs-cats\", 在裡面創建另一個資料夾\"train\"，將下載的壓縮檔當中的 train 壓縮黨裡面的資料都解壓縮到裡面。 <br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# 解壓縮資料夾所在的目錄路徑\n",
    "original_dataset_dir = r'./dogs-vs-cats/train' \n",
    "# 用來儲存少量資料集的目錄位置\n",
    "base_dir = r'./cats_and_dogs_small' \n",
    "if not os.path.isdir(base_dir): os.mkdir(base_dir)  # 如果目錄不存在, 才建立目錄\n",
    "\n",
    "# 分拆成訓練、驗證與測試目錄位置\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "if not os.path.isdir(train_dir): os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')  \n",
    "if not os.path.isdir(validation_dir): os.mkdir(validation_dir)\n",
    "    \n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "if not os.path.isdir(test_dir): os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "if not os.path.isdir(train_cats_dir): \n",
    "    os.mkdir(train_cats_dir) # 用來訓練貓圖片的目錄位置\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "if not os.path.isdir(train_dogs_dir): \n",
    "    os.mkdir(train_dogs_dir) # 用來訓練狗圖片的目錄位置\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "if not os.path.isdir(validation_cats_dir): \n",
    "    os.mkdir(validation_cats_dir) # 用來驗證貓圖片的目錄位置\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "if not os.path.isdir(validation_dogs_dir): \n",
    "    os.mkdir(validation_dogs_dir) # 用來驗證狗圖片的目錄位置\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "if not os.path.isdir(test_cats_dir): \n",
    "    os.mkdir(test_cats_dir) # 用來測試貓圖片的目錄位置\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "if not os.path.isdir(test_dogs_dir): \n",
    "    os.mkdir(test_dogs_dir) # 用來測試狗圖片的目錄位置\n",
    "\n",
    "# 複製前面 1000 張貓圖片到 train_cats_dir 訓練目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張貓圖片到 validation_cats_dir 驗證目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張貓圖片到 test_cats_dir 測試目錄\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製前面 1000 張狗圖片到 train_dogs_dir 訓練目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張狗圖片到 validation_dogs_dir 驗證目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "# 複製下 500 張狗圖片到 test_dogs_dir 測試目錄\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "print('複製完成')\n",
    "print('訓練用的貓照片張數:', len(os.listdir(train_cats_dir)))\n",
    "print('訓練用的狗照片張數:', len(os.listdir(train_dogs_dir)))\n",
    "print('驗證用的貓照片張數:', len(os.listdir(validation_cats_dir)))\n",
    "print('驗證用的狗照片張數:', len(os.listdir(validation_dogs_dir)))\n",
    "print('測試用的貓照片張數:', len(os.listdir(test_cats_dir)))\n",
    "print('測試用的狗照片張數:', len(os.listdir(test_dogs_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout\n",
    "from keras.layers import Activation, Flatten, Input\n",
    "def buildModel(type):\n",
    "    if(type == 'A'):\n",
    "        model = Sequential([\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same', input_shape=(150, 150, 3)),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            Dense(64, activation = 'relu'),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    elif(type == 'B'):\n",
    "        model = Sequential([\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same', input_shape=(150, 150, 3)),\n",
    "            Conv2D(4, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(8, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(16, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(32, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            Conv2D(64, (3, 3), activation = 'relu', padding = 'same'),\n",
    "            MaxPooling2D((2, 2), strides=(2,2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation = 'relu'),\n",
    "            Dense(64, activation = 'relu'),\n",
    "            Dense(1, activation = 'sigmoid')\n",
    "        ])\n",
    "        return model\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20, \n",
    "    class_mode='binary' # 兩個 class \n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "# for data_batch, labels_batch in train_generator:\n",
    "#     print('data batch shape:', data_batch.shape)\n",
    "#     print('labels batch shape:', labels_batch.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('A')\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 1e-4), metrics='acc')\n",
    "# 使用 fit 能跟 fit_generator 做到相同的效果 (較新的版本), 如果無法使用, 改用 fit_generator\n",
    "historyA = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "# 存模型\n",
    "model.save('cats_and_dogs_small_A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('B')\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(learning_rate = 1e-4), metrics='acc')\n",
    "# 使用 fit 能跟 fit_generator 做到相同的效果 (較新的版本), 如果無法使用, 改用 fit_generator\n",
    "historyB = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "# 存模型\n",
    "model.save('cats_and_dogs_small_B.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def showHistory(history, name):\n",
    "    # 把訓練過程畫出來\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig(name+'acc.png')\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(name+'loss.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHistory(historyA, \"A\")\n",
    "showHistory(historyB, \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 經過擴充處理過後產出的圖片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定產生圖片的參數, 旋轉, 平移, 左右翻轉, 填充模式...\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random \n",
    "\n",
    "# 貓\n",
    "cats_dir = \"./cats\"\n",
    "if not os.path.isdir(cats_dir): os.mkdir(cats_dir)\n",
    "\n",
    "# 顯示圖片產生器產出的東西\n",
    "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
    "# img_path = fnames[20]\n",
    "for i in range(15):\n",
    "    img_name = \"S1154041_\" + str(i+1)\n",
    "    index = random.randint(0, len(fnames))\n",
    "    img_path = fnames[index]\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(150, 150))\n",
    "    imgarr = tf.keras.utils.img_to_array(img)\n",
    "    imgarr = imgarr.reshape((1, ) + imgarr.shape)\n",
    "    j = 0\n",
    "    dice = random.randint(0, 4)\n",
    "    for batch in datagen.flow(imgarr, batch_size=1):\n",
    "        plt.figure(j)\n",
    "        plt.axis('off')\n",
    "        imgplot = plt.imshow(tf.keras.utils.array_to_img(batch[0]))\n",
    "        # plt.savefig(cats_dir + \"/\" + img_name + \"_\" + str(j+1) + \".png\")\n",
    "        if(j == dice):\n",
    "            plt.savefig(cats_dir + \"/\" + img_name + \".png\")\n",
    "        j += 1\n",
    "        if j % 4 == 0:\n",
    "            break\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 狗\n",
    "dogs_dir = \"./dogs\"\n",
    "if not os.path.isdir(dogs_dir): os.mkdir(dogs_dir)\n",
    "\n",
    "# 顯示圖片產生器產出的東西\n",
    "fnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n",
    "# img_path = fnames[20]\n",
    "for i in range(15):\n",
    "    img_name = \"S1154041_\" + str(i+1)\n",
    "    index = random.randint(0, len(fnames))\n",
    "    img_path = fnames[index]\n",
    "    img = tf.keras.utils.load_img(img_path, target_size=(150, 150))\n",
    "    imgarr = tf.keras.utils.img_to_array(img)\n",
    "    imgarr = imgarr.reshape((1, ) + imgarr.shape)\n",
    "    j = 0\n",
    "    dice = random.randint(0, 4)\n",
    "    for batch in datagen.flow(imgarr, batch_size=1):\n",
    "        plt.figure(j)\n",
    "        plt.axis('off')\n",
    "        imgplot = plt.imshow(tf.keras.utils.array_to_img(batch[0]))\n",
    "        # plt.savefig(dogs_dir + \"/\" + img_name + \"_\" + str(j+1) + \".png\")\n",
    "        if(j == dice): \n",
    "            plt.savefig(dogs_dir + \"/\" + img_name + \".png\")\n",
    "        j += 1\n",
    "        if j % 4 == 0:\n",
    "            break\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 產生圖片過後再訓練一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('A')\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255) # 驗證集不需要擴充, 跟之前一樣\n",
    "# 設定產生圖片的參數, 旋轉, 平移, 左右翻轉, 填充模式...\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255, \n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "train_samples = train_generator.samples\n",
    "validation_samples = validation_generator.samples\n",
    "batch_size = 32\n",
    "steps_per_epoch = train_samples // batch_size\n",
    "validation_steps = validation_samples // batch_size\n",
    "# historyA_extend = model.fit(\n",
    "#     train_generator,\n",
    "#     steps_per_epoch=steps_per_epoch,\n",
    "#     epochs=30,\n",
    "#     validation_data=validation_generator,\n",
    "#     validation_steps=validation_steps\n",
    "# )\n",
    "historyA_extend = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "model.save('cats_and_dogs_small_A_extend.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buildModel('B')\n",
    "model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(learning_rate=1e-4), metrics=['acc'])\n",
    "historyB_extend = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50\n",
    ")\n",
    "model.save('cats_and_dogs_small_B_extend.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showHistory(historyA_extend, \"A_extend_\")\n",
    "showHistory(historyB_extend, \"B_extend_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"cats_and_dogs_small_A.h5\")\n",
    "model.summary()\n",
    "model = tf.keras.models.load_model(\"cats_and_dogs_small_B.h5\")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
